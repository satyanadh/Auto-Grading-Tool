{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0ffa99ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import Compose, ToTensor, Lambda\n",
    "from torchvision.transforms.functional import rotate, hflip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3505c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = \"emnistbyclass\"\n",
    "# name = \"emnistbalanced\"\n",
    "name = \"emnistbalanced_mathsymbols_custom\"\n",
    "# name = \"mnist\"\n",
    "# name = \"mathsymbols\"\n",
    "# name = \"mnist_mathsymbols\"\n",
    "# name = \"emnistbyclass_mathsymbols\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3bc9b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMNIST dataset\n",
    "# split = \"byclass\"\n",
    "# split = 'bymerge'\n",
    "split = \"balanced\"\n",
    "# split = 'letters'\n",
    "# split = 'digits'\n",
    "# split = \"mnist\"\n",
    "emnist_train_data = datasets.EMNIST(\n",
    "    root=\"data\",\n",
    "    split=split,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=Compose([lambda img: rotate(img, -90), lambda img: hflip(img), ToTensor()]),\n",
    "    target_transform=Lambda(lambda y: torch.tensor(y)),\n",
    ")\n",
    "emnist_test_data = datasets.EMNIST(\n",
    "    root=\"data\",\n",
    "    split=split,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=Compose([lambda img: rotate(img, -90), lambda img: hflip(img), ToTensor()]),\n",
    "    target_transform=Lambda(lambda y: torch.tensor(y)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f0f9e79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'd', 'e', 'f', 'g', 'h', 'n', 'q', 'r', 't', 'gt', 'lt', '(', ')', '[', ']', '=', '-', '+', 'colon', 'decimal', 'multiply', 'divide', 'comma']\n"
     ]
    }
   ],
   "source": [
    "# EMNIST balanced has 2400 train samples and 400 test samples per class\n",
    "target_train_samples = 2400\n",
    "target_test_samples = 400\n",
    "\n",
    "math_symbols = [\"gt\", \"lt\", \"(\", \")\", \"[\", \"]\", \"=\", \"-\", \"+\"]\n",
    "custom_symbols = [\"colon\", \"decimal\", \"multiply\", \"divide\", \"comma\"]\n",
    "\n",
    "class_names = []\n",
    "\n",
    "if \"mnist\" in name:\n",
    "    class_names += [str(num) for num in range(10)]\n",
    "\n",
    "if \"emnist\" in name:\n",
    "    class_names += [chr(capital) for capital in range(ord(\"A\"), ord(\"Z\") + 1)]\n",
    "    class_names += [chr(lower) for lower in range(ord(\"a\"), ord(\"z\") + 1)]\n",
    "\n",
    "if \"balanced\" in name:\n",
    "    class_names = [\n",
    "        x\n",
    "        for x in class_names\n",
    "        if x not in {\"c\", \"i\", \"j\", \"k\", \"l\", \"m\", \"o\", \"p\", \"s\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"}\n",
    "    ]\n",
    "\n",
    "if \"math\" in name:\n",
    "    class_names += math_symbols\n",
    "\n",
    "if \"custom\" in name:\n",
    "    class_names += custom_symbols\n",
    "\n",
    "print(len(class_names))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "789552ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Math symbols train size: 21600\n",
      "Math symbols test size: 2227\n"
     ]
    }
   ],
   "source": [
    "# Math Symbols dataset\n",
    "class MathSymbolsDataset(Dataset):\n",
    "    def __init__(self, img_labels, transform=None, target_transform=None):\n",
    "        self.img_labels = img_labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_labels.iloc[idx, 0]\n",
    "\n",
    "        im = cv2.imread(img_path)\n",
    "\n",
    "        # Grayscale\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Flip black and white\n",
    "        im = cv2.bitwise_not(im)\n",
    "\n",
    "        # Make lines thicker\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4, 4))\n",
    "        im = cv2.dilate(im, kernel, iterations=1)\n",
    "\n",
    "        # Gaussian blur\n",
    "        im = cv2.GaussianBlur(im, ksize=(3, 3), sigmaX=1, sigmaY=1)\n",
    "\n",
    "        # Resize to 24x24\n",
    "        im = cv2.resize(im, (24, 24), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # Add 2 pixel border for total size of 28x28\n",
    "        border = 2\n",
    "        im = cv2.copyMakeBorder(\n",
    "            im, border, border, border, border, cv2.BORDER_CONSTANT, value=(0, 0, 0)\n",
    "        )\n",
    "\n",
    "        # Normalize\n",
    "        im = im / 255\n",
    "\n",
    "        # Convert to tensor\n",
    "        image = torch.from_numpy(im.astype(\"float32\")).unsqueeze(0)\n",
    "\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        label = torch.tensor(label).type(torch.LongTensor)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "math_symbols_root = \"data/math_symbols\"\n",
    "train_datasets = []\n",
    "test_datasets = []\n",
    "\n",
    "for i, symbol in enumerate(math_symbols):\n",
    "    # Get data as an array\n",
    "    data = []\n",
    "    root = f\"{math_symbols_root}/{symbol}\"\n",
    "    for file in glob.glob(f\"{root}/**/*.jpg\", recursive=True):\n",
    "        path = file.replace(\"\\\\\", \"/\")\n",
    "        label = i\n",
    "        data.append([path, label])\n",
    "    data = np.array(data)\n",
    "\n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame(columns=[\"path\", \"label\"])\n",
    "    df[\"path\"] = data[:, 0]\n",
    "    df[\"label\"] = data[:, 1].astype(int)\n",
    "    offset = 0\n",
    "    if \"mnist\" in name:\n",
    "        offset += 10\n",
    "    if \"emnist\" in name:\n",
    "        offset += 52\n",
    "    if \"balanced\" in name:\n",
    "        offset -= 15\n",
    "    df[\"label\"] = df[\"label\"] + offset\n",
    "\n",
    "    # Calculate number of test samples\n",
    "    test_samples = int(0.1 * len(df))\n",
    "    remaining = len(df) - test_samples\n",
    "    if remaining > target_train_samples:\n",
    "        dif = remaining - target_train_samples\n",
    "        test_samples = min(target_test_samples, test_samples + dif)\n",
    "\n",
    "    # Split train/test\n",
    "    train_df = df.iloc[test_samples:]\n",
    "    test_df = df.iloc[:test_samples]\n",
    "\n",
    "    # Over or under sample train set only\n",
    "    if len(train_df) != target_train_samples:\n",
    "        train_df = train_df.sample(\n",
    "            n=target_train_samples, replace=(len(train_df) < target_train_samples), random_state=42\n",
    "        )\n",
    "\n",
    "    train_dataset = MathSymbolsDataset(train_df)\n",
    "    test_dataset = MathSymbolsDataset(test_df)\n",
    "\n",
    "    train_datasets.append(train_dataset)\n",
    "    test_datasets.append(test_dataset)\n",
    "\n",
    "math_symbols_train_data = ConcatDataset(train_datasets)\n",
    "math_symbols_test_data = ConcatDataset(test_datasets)\n",
    "\n",
    "print(\"Math symbols train size:\", len(math_symbols_train_data))\n",
    "print(\"Math symbols test size:\", len(math_symbols_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7e62cb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom symbols train size: 12000\n",
      "Custom symbols test size: 55\n"
     ]
    }
   ],
   "source": [
    "# Custom Symbols dataset\n",
    "class CustomSymbolsDataset(Dataset):\n",
    "    def __init__(self, img_labels, transform=None, target_transform=None):\n",
    "        self.img_labels = img_labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_labels.iloc[idx, 0]\n",
    "\n",
    "        im = cv2.imread(img_path)\n",
    "\n",
    "        # Grayscale\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Normalize\n",
    "        im = im / 255\n",
    "\n",
    "        # Convert to tensor\n",
    "        image = torch.from_numpy(im.astype(\"float32\")).unsqueeze(0)\n",
    "\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        label = torch.tensor(label).type(torch.LongTensor)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "custom_symbols_root = \"data/custom_symbols\"\n",
    "train_datasets = []\n",
    "test_datasets = []\n",
    "\n",
    "for i, symbol in enumerate(custom_symbols):\n",
    "    # Get data as an array\n",
    "    data = []\n",
    "    root = f\"{custom_symbols_root}/{symbol}\"\n",
    "    for file in glob.glob(f\"{root}/**/*.jpg\", recursive=True):\n",
    "        path = file.replace(\"\\\\\", \"/\")\n",
    "        label = i\n",
    "        data.append([path, label])\n",
    "    data = np.array(data)\n",
    "\n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame(columns=[\"path\", \"label\"])\n",
    "    df[\"path\"] = data[:, 0]\n",
    "    df[\"label\"] = data[:, 1].astype(int)\n",
    "    offset = 0\n",
    "    if \"mnist\" in name:\n",
    "        offset += 10\n",
    "    if \"emnist\" in name:\n",
    "        offset += 52\n",
    "    if \"balanced\" in name:\n",
    "        offset -= 15\n",
    "    if \"math\" in name:\n",
    "        offset += len(math_symbols)\n",
    "    df[\"label\"] = df[\"label\"] + offset\n",
    "\n",
    "    # Calculate number of test samples\n",
    "    test_samples = int(0.1 * len(df))\n",
    "    remaining = len(df) - test_samples\n",
    "    if remaining > target_train_samples:\n",
    "        dif = remaining - target_train_samples\n",
    "        test_samples = min(target_test_samples, test_samples + dif)\n",
    "\n",
    "    # Split train/test\n",
    "    train_df = df.iloc[test_samples:]\n",
    "    test_df = df.iloc[:test_samples]\n",
    "\n",
    "    # Over or under sample train set only\n",
    "    if len(train_df) != target_train_samples:\n",
    "        train_df = train_df.sample(\n",
    "            n=target_train_samples, replace=(len(train_df) < target_train_samples), random_state=42\n",
    "        )\n",
    "\n",
    "    train_dataset = CustomSymbolsDataset(train_df)\n",
    "    test_dataset = CustomSymbolsDataset(test_df)\n",
    "\n",
    "    train_datasets.append(train_dataset)\n",
    "    test_datasets.append(test_dataset)\n",
    "\n",
    "custom_symbols_train_data = ConcatDataset(train_datasets)\n",
    "custom_symbols_test_data = ConcatDataset(test_datasets)\n",
    "\n",
    "print(\"Custom symbols train size:\", len(custom_symbols_train_data))\n",
    "print(\"Custom symbols test size:\", len(custom_symbols_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "14b1a0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "if \"mnist\" in name:\n",
    "    train_data.append(emnist_train_data)\n",
    "    test_data.append(emnist_test_data)\n",
    "\n",
    "if \"math\" in name:\n",
    "    train_data.append(math_symbols_train_data)\n",
    "    test_data.append(math_symbols_test_data)\n",
    "\n",
    "if \"custom\" in name:\n",
    "    train_data.append(custom_symbols_train_data)\n",
    "    test_data.append(custom_symbols_test_data)\n",
    "\n",
    "if len(train_data) == 1:\n",
    "    train_data = train_data[0]\n",
    "    test_data = test_data[0]\n",
    "else:\n",
    "    train_data = ConcatDataset(train_data)\n",
    "    test_data = ConcatDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3c399c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: D\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(0, len(train_data))\n",
    "sample_img, sample_label = train_data[idx]\n",
    "plt.imshow(sample_img.reshape(28, 28), cmap=\"gray\")\n",
    "print(\"Label:\", class_names[sample_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e956f1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_classes: 61\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# for X, y in test_dataloader:\n",
    "#     print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "#     print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "#     break\n",
    "\n",
    "n_classes = len(class_names)\n",
    "print(\"n_classes:\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "89cb1ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "CNN(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "    (7): ReLU()\n",
      "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): Dropout(p=0.1, inplace=False)\n",
      "    (10): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (14): ReLU()\n",
      "    (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "    (17): ReLU()\n",
      "    (18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.1, inplace=False)\n",
      "    (1): Linear(in_features=25600, out_features=128, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Dropout(p=0.1, inplace=False)\n",
      "    (5): Linear(in_features=128, out_features=61, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(in_features=64 * 20 * 20, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(in_features=128, out_features=n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = CNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "70b411ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ffcc675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e6cb7d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    preds = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            labels += y.tolist()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            preds += pred.argmax(1).tolist()\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2da2a569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4.246937  [   64/146400]\n",
      "loss: 0.620102  [ 6464/146400]\n",
      "loss: 0.583409  [12864/146400]\n",
      "loss: 0.503774  [19264/146400]\n",
      "loss: 0.396935  [25664/146400]\n",
      "loss: 0.349742  [32064/146400]\n",
      "loss: 0.311828  [38464/146400]\n",
      "loss: 0.242328  [44864/146400]\n",
      "loss: 0.295377  [51264/146400]\n",
      "loss: 0.297786  [57664/146400]\n",
      "loss: 0.370519  [64064/146400]\n",
      "loss: 0.266341  [70464/146400]\n",
      "loss: 0.334639  [76864/146400]\n",
      "loss: 0.213533  [83264/146400]\n",
      "loss: 0.338100  [89664/146400]\n",
      "loss: 0.405100  [96064/146400]\n",
      "loss: 0.498435  [102464/146400]\n",
      "loss: 0.299384  [108864/146400]\n",
      "loss: 0.252144  [115264/146400]\n",
      "loss: 0.158673  [121664/146400]\n",
      "loss: 0.313376  [128064/146400]\n",
      "loss: 0.458753  [134464/146400]\n",
      "loss: 0.317596  [140864/146400]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.348189 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.245633  [   64/146400]\n",
      "loss: 0.358586  [ 6464/146400]\n",
      "loss: 0.277755  [12864/146400]\n",
      "loss: 0.304833  [19264/146400]\n",
      "loss: 0.189216  [25664/146400]\n",
      "loss: 0.210629  [32064/146400]\n",
      "loss: 0.251930  [38464/146400]\n",
      "loss: 0.224839  [44864/146400]\n",
      "loss: 0.270693  [51264/146400]\n",
      "loss: 0.278695  [57664/146400]\n",
      "loss: 0.442468  [64064/146400]\n",
      "loss: 0.239017  [70464/146400]\n",
      "loss: 0.340357  [76864/146400]\n",
      "loss: 0.561853  [83264/146400]\n",
      "loss: 0.119904  [89664/146400]\n",
      "loss: 0.331945  [96064/146400]\n",
      "loss: 0.174096  [102464/146400]\n",
      "loss: 0.325854  [108864/146400]\n",
      "loss: 0.339304  [115264/146400]\n",
      "loss: 0.220999  [121664/146400]\n",
      "loss: 0.282158  [128064/146400]\n",
      "loss: 0.208131  [134464/146400]\n",
      "loss: 0.264176  [140864/146400]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.304507 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.119342  [   64/146400]\n",
      "loss: 0.161420  [ 6464/146400]\n",
      "loss: 0.242246  [12864/146400]\n",
      "loss: 0.179744  [19264/146400]\n",
      "loss: 0.189810  [25664/146400]\n",
      "loss: 0.192793  [32064/146400]\n",
      "loss: 0.295199  [38464/146400]\n",
      "loss: 0.210533  [44864/146400]\n",
      "loss: 0.266604  [51264/146400]\n",
      "loss: 0.109315  [57664/146400]\n",
      "loss: 0.345700  [64064/146400]\n",
      "loss: 0.135015  [70464/146400]\n",
      "loss: 0.191432  [76864/146400]\n",
      "loss: 0.278863  [83264/146400]\n",
      "loss: 0.243807  [89664/146400]\n",
      "loss: 0.107877  [96064/146400]\n",
      "loss: 0.231580  [102464/146400]\n",
      "loss: 0.227776  [108864/146400]\n",
      "loss: 0.177545  [115264/146400]\n",
      "loss: 0.210485  [121664/146400]\n",
      "loss: 0.146065  [128064/146400]\n",
      "loss: 0.305547  [134464/146400]\n",
      "loss: 0.258313  [140864/146400]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.305432 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.138624  [   64/146400]\n",
      "loss: 0.191072  [ 6464/146400]\n",
      "loss: 0.175827  [12864/146400]\n",
      "loss: 0.285041  [19264/146400]\n",
      "loss: 0.192613  [25664/146400]\n",
      "loss: 0.122918  [32064/146400]\n",
      "loss: 0.234132  [38464/146400]\n",
      "loss: 0.153412  [44864/146400]\n",
      "loss: 0.101578  [51264/146400]\n",
      "loss: 0.076633  [57664/146400]\n",
      "loss: 0.183992  [64064/146400]\n",
      "loss: 0.206514  [70464/146400]\n",
      "loss: 0.139466  [76864/146400]\n",
      "loss: 0.177759  [83264/146400]\n",
      "loss: 0.458840  [89664/146400]\n",
      "loss: 0.305263  [96064/146400]\n",
      "loss: 0.183805  [102464/146400]\n",
      "loss: 0.050719  [108864/146400]\n",
      "loss: 0.186223  [115264/146400]\n",
      "loss: 0.372482  [121664/146400]\n",
      "loss: 0.286330  [128064/146400]\n",
      "loss: 0.116974  [134464/146400]\n",
      "loss: 0.295617  [140864/146400]\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.285885 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.123981  [   64/146400]\n",
      "loss: 0.084660  [ 6464/146400]\n",
      "loss: 0.218278  [12864/146400]\n",
      "loss: 0.124716  [19264/146400]\n",
      "loss: 0.156813  [25664/146400]\n",
      "loss: 0.125483  [32064/146400]\n",
      "loss: 0.146148  [38464/146400]\n",
      "loss: 0.148257  [44864/146400]\n",
      "loss: 0.190537  [51264/146400]\n",
      "loss: 0.098588  [57664/146400]\n",
      "loss: 0.106934  [64064/146400]\n",
      "loss: 0.286542  [70464/146400]\n",
      "loss: 0.273494  [76864/146400]\n",
      "loss: 0.148672  [83264/146400]\n",
      "loss: 0.210025  [89664/146400]\n",
      "loss: 0.256902  [96064/146400]\n",
      "loss: 0.110634  [102464/146400]\n",
      "loss: 0.160008  [108864/146400]\n",
      "loss: 0.313393  [115264/146400]\n",
      "loss: 0.183880  [121664/146400]\n",
      "loss: 0.164086  [128064/146400]\n",
      "loss: 0.046730  [134464/146400]\n",
      "loss: 0.336277  [140864/146400]\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.300908 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.134724  [   64/146400]\n",
      "loss: 0.126592  [ 6464/146400]\n",
      "loss: 0.206348  [12864/146400]\n",
      "loss: 0.117768  [19264/146400]\n",
      "loss: 0.071377  [25664/146400]\n",
      "loss: 0.242368  [32064/146400]\n",
      "loss: 0.190129  [38464/146400]\n",
      "loss: 0.284518  [44864/146400]\n",
      "loss: 0.156328  [51264/146400]\n",
      "loss: 0.301343  [57664/146400]\n",
      "loss: 0.108911  [64064/146400]\n",
      "loss: 0.210918  [70464/146400]\n",
      "loss: 0.195160  [76864/146400]\n",
      "loss: 0.198628  [83264/146400]\n",
      "loss: 0.155391  [89664/146400]\n",
      "loss: 0.185139  [96064/146400]\n",
      "loss: 0.191839  [102464/146400]\n",
      "loss: 0.196236  [108864/146400]\n",
      "loss: 0.247750  [115264/146400]\n",
      "loss: 0.276818  [121664/146400]\n",
      "loss: 0.077020  [128064/146400]\n",
      "loss: 0.088406  [134464/146400]\n",
      "loss: 0.097730  [140864/146400]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.307277 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.150172  [   64/146400]\n",
      "loss: 0.140805  [ 6464/146400]\n",
      "loss: 0.095581  [12864/146400]\n",
      "loss: 0.140523  [19264/146400]\n",
      "loss: 0.145216  [25664/146400]\n",
      "loss: 0.167114  [32064/146400]\n",
      "loss: 0.215168  [38464/146400]\n",
      "loss: 0.085245  [44864/146400]\n",
      "loss: 0.116596  [51264/146400]\n",
      "loss: 0.183933  [57664/146400]\n",
      "loss: 0.145190  [64064/146400]\n",
      "loss: 0.193561  [70464/146400]\n",
      "loss: 0.264076  [76864/146400]\n",
      "loss: 0.121048  [83264/146400]\n",
      "loss: 0.145602  [89664/146400]\n",
      "loss: 0.046888  [96064/146400]\n",
      "loss: 0.240146  [102464/146400]\n",
      "loss: 0.159033  [108864/146400]\n",
      "loss: 0.180971  [115264/146400]\n",
      "loss: 0.145252  [121664/146400]\n",
      "loss: 0.231289  [128064/146400]\n",
      "loss: 0.154453  [134464/146400]\n",
      "loss: 0.137119  [140864/146400]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.307666 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.123440  [   64/146400]\n",
      "loss: 0.082768  [ 6464/146400]\n",
      "loss: 0.162513  [12864/146400]\n",
      "loss: 0.126927  [19264/146400]\n",
      "loss: 0.103222  [25664/146400]\n",
      "loss: 0.095668  [32064/146400]\n",
      "loss: 0.144388  [38464/146400]\n",
      "loss: 0.243893  [44864/146400]\n",
      "loss: 0.203191  [51264/146400]\n",
      "loss: 0.137987  [57664/146400]\n",
      "loss: 0.181125  [64064/146400]\n",
      "loss: 0.142860  [70464/146400]\n",
      "loss: 0.163057  [76864/146400]\n",
      "loss: 0.152619  [83264/146400]\n",
      "loss: 0.068470  [89664/146400]\n",
      "loss: 0.171237  [96064/146400]\n",
      "loss: 0.121602  [102464/146400]\n",
      "loss: 0.146832  [108864/146400]\n",
      "loss: 0.150219  [115264/146400]\n",
      "loss: 0.094794  [121664/146400]\n",
      "loss: 0.126707  [128064/146400]\n",
      "loss: 0.156648  [134464/146400]\n",
      "loss: 0.109724  [140864/146400]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.337376 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.070038  [   64/146400]\n",
      "loss: 0.157597  [ 6464/146400]\n",
      "loss: 0.079921  [12864/146400]\n",
      "loss: 0.055963  [19264/146400]\n",
      "loss: 0.138378  [25664/146400]\n",
      "loss: 0.071242  [32064/146400]\n",
      "loss: 0.108959  [38464/146400]\n",
      "loss: 0.114541  [44864/146400]\n",
      "loss: 0.132295  [51264/146400]\n",
      "loss: 0.239051  [57664/146400]\n",
      "loss: 0.041189  [64064/146400]\n",
      "loss: 0.057599  [70464/146400]\n",
      "loss: 0.103069  [76864/146400]\n",
      "loss: 0.095391  [83264/146400]\n",
      "loss: 0.098774  [89664/146400]\n",
      "loss: 0.213983  [96064/146400]\n",
      "loss: 0.205050  [102464/146400]\n",
      "loss: 0.048365  [108864/146400]\n",
      "loss: 0.129783  [115264/146400]\n",
      "loss: 0.163161  [121664/146400]\n",
      "loss: 0.128873  [128064/146400]\n",
      "loss: 0.173328  [134464/146400]\n",
      "loss: 0.125642  [140864/146400]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.349867 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.236573  [   64/146400]\n",
      "loss: 0.042595  [ 6464/146400]\n",
      "loss: 0.171354  [12864/146400]\n",
      "loss: 0.086636  [19264/146400]\n",
      "loss: 0.067736  [25664/146400]\n",
      "loss: 0.120318  [32064/146400]\n",
      "loss: 0.050107  [38464/146400]\n",
      "loss: 0.078248  [44864/146400]\n",
      "loss: 0.089098  [51264/146400]\n",
      "loss: 0.108167  [57664/146400]\n",
      "loss: 0.073276  [64064/146400]\n",
      "loss: 0.186297  [70464/146400]\n",
      "loss: 0.077932  [76864/146400]\n",
      "loss: 0.136408  [83264/146400]\n",
      "loss: 0.160401  [89664/146400]\n",
      "loss: 0.096390  [96064/146400]\n",
      "loss: 0.064407  [102464/146400]\n",
      "loss: 0.060995  [108864/146400]\n",
      "loss: 0.057776  [115264/146400]\n",
      "loss: 0.137315  [121664/146400]\n",
      "loss: 0.072237  [128064/146400]\n",
      "loss: 0.152110  [134464/146400]\n",
      "loss: 0.101153  [140864/146400]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.372144 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b7f7b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"model_{name}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cc55c4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "model.load_state_dict(torch.load(f\"model_{name}.pth\"))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d7b81573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"I\", Actual: \"I\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14b9a4034c0>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "idx = np.random.randint(0, len(test_data))\n",
    "x, y = test_data[idx]\n",
    "with torch.no_grad():\n",
    "    x = x.unsqueeze(0)\n",
    "    pred = model(x.to(device))\n",
    "    predicted, actual = class_names[pred[0].argmax(0)], class_names[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
    "plt.imshow(x.reshape(28, 28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3ef38688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.372110 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds, labels = test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "521a05c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 197/400 (49.2%)\n",
      "L: 212/400 (53.0%)\n",
      "1: 219/400 (54.8%)\n",
      "q: 248/400 (62.0%)\n",
      "f: 258/400 (64.5%)\n",
      "F: 263/400 (65.8%)\n",
      "I: 264/400 (66.0%)\n",
      "g: 269/400 (67.2%)\n",
      "O: 320/400 (80.0%)\n",
      "9: 321/400 (80.2%)\n",
      "a: 346/400 (86.5%)\n",
      "V: 350/400 (87.5%)\n",
      "2: 352/400 (88.0%)\n",
      "t: 358/400 (89.5%)\n",
      "D: 360/400 (90.0%)\n",
      "5: 360/400 (90.0%)\n",
      "n: 360/400 (90.0%)\n",
      "T: 363/400 (90.8%)\n",
      "b: 367/400 (91.8%)\n",
      "Y: 368/400 (92.0%)\n",
      "Z: 371/400 (92.8%)\n",
      "S: 373/400 (93.2%)\n",
      "4: 374/400 (93.5%)\n",
      "J: 378/400 (94.5%)\n",
      "h: 379/400 (94.8%)\n",
      "6: 379/400 (94.8%)\n",
      "8: 379/400 (94.8%)\n",
      "r: 380/400 (95.0%)\n",
      "U: 381/400 (95.2%)\n",
      "P: 383/400 (95.8%)\n",
      "G: 385/400 (96.2%)\n",
      "C: 385/400 (96.2%)\n",
      "d: 386/400 (96.5%)\n",
      "Q: 386/400 (96.5%)\n",
      "X: 387/400 (96.8%)\n",
      "N: 388/400 (97.0%)\n",
      "B: 388/400 (97.0%)\n",
      "M: 389/400 (97.2%)\n",
      "7: 389/400 (97.2%)\n",
      "W: 390/400 (97.5%)\n",
      "e: 390/400 (97.5%)\n",
      "E: 393/400 (98.2%)\n",
      "H: 393/400 (98.2%)\n",
      "K: 393/400 (98.2%)\n",
      "R: 393/400 (98.2%)\n",
      "A: 394/400 (98.5%)\n",
      "3: 397/400 (99.2%)\n",
      "+: 398/400 (99.5%)\n",
      "=: 398/400 (99.5%)\n",
      "-: 398/400 (99.5%)\n",
      "(: 399/400 (99.8%)\n",
      "): 400/400 (100.0%)\n",
      "]: 78/78 (100.0%)\n",
      "colon: 11/11 (100.0%)\n",
      "[: 77/77 (100.0%)\n",
      "lt: 47/47 (100.0%)\n",
      "divide: 11/11 (100.0%)\n",
      "comma: 11/11 (100.0%)\n",
      "gt: 25/25 (100.0%)\n",
      "multiply: 11/11 (100.0%)\n",
      "decimal: 11/11 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "correct = dict()\n",
    "label_counts = dict()\n",
    "for i in range(len(preds)):\n",
    "    pred = preds[i]\n",
    "    label = labels[i]\n",
    "    label_counts[label] = label_counts.get(label, 0) + 1\n",
    "    if pred == label:\n",
    "        correct[label] = correct.get(label, 0) + 1\n",
    "test_results = []\n",
    "for idx, cor in correct.items():\n",
    "    label_count = label_counts[idx]\n",
    "    class_name = class_names[idx]\n",
    "    perc = round(cor / label_count * 100, 1)\n",
    "    test_results.append((class_name, cor, label_count, perc))\n",
    "test_results.sort(key=lambda x: x[3])\n",
    "for class_name, cor, label_count, perc in test_results:\n",
    "    print(f\"{class_name}: {cor}/{label_count} ({perc}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "71985a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r': 2400, 'a': 2400, 'n': 2400, 'F': 2400, '4': 2400, 'h': 2400, 'Q': 2400, 'W': 2400, 'K': 2400, '1': 2400, 't': 2400, 'D': 2400, 'O': 2400, 'C': 2400, '5': 2400, 'H': 2400, '3': 2400, 'f': 2400, 'E': 2400, 'q': 2400, 'J': 2400, 'T': 2400, 'P': 2400, 'Z': 2400, 'S': 2400, 'N': 2400, 'M': 2400, 'Y': 2400, '9': 2400, 'U': 2400, 'd': 2400, 'e': 2400, 'b': 2400, 'V': 2400, 'G': 2400, '7': 2400, '2': 2400, '8': 2400, 'A': 2400, '6': 2400, 'R': 2400, 'X': 2400, 'B': 2400, 'I': 2400, 'g': 2400, '0': 2400, 'L': 2400, 'gt': 2400, 'lt': 2400, '(': 2400, ')': 2400, '[': 2400, ']': 2400, '=': 2400, '-': 2400, '+': 2400, 'colon': 2400, 'decimal': 2400, 'multiply': 2400, 'divide': 2400, 'comma': 2400}\n"
     ]
    }
   ],
   "source": [
    "counts = dict()\n",
    "for img, label in train_data:\n",
    "    class_name = class_names[label.item()]\n",
    "    counts[class_name] = counts.get(class_name, 0) + 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb427c62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmpe295",
   "language": "python",
   "name": "cmpe295"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
